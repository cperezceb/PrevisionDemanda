{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width: 100%; clear: both;\">\n",
    "<div style=\"float: left; width: 50%;\">\n",
    "<img src=\"http://www.uoc.edu/portal/_resources/common/imatges/marca_UOC/UOC_Masterbrand.jpg\", align=\"left\">\n",
    "</div>\n",
    "<div style=\"float: right; width: 50%;\">\n",
    "<p style=\"margin: 0; padding-top: 22px; text-align:right;\">TFM - Previsión de demanda mediante uso de técnicas de machine learning\n",
    "</p>\n",
    "<p style=\"margin: 0; text-align:right;\">Máster universitario en Ciencia de datos (Data science)</p>\n",
    "<p style=\"margin: 0; text-align:right; padding-button: 100px;\">Carlos Pérez Cebrián</p>\n",
    "</div>\n",
    "</div>\n",
    "<div style=\"width:100%;\">&nbsp;</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR (Support Vector Regression) o SVM en regresión\n",
    "\n",
    "Las Support Vector Machine (SVM) se fundamentan en el _Maximal Margin Classifier_, que a su vez, se basan en el concepto de hiperplano.\n",
    "\n",
    "En un espacio p-dimensional, un hiperplano se define como un subespacio plano y afín de dimensiones p-1. El término afín significa que el subespacio no debe pasar por el origen. En un espacio de dos dimensiones, el hiperplano es un subespacio de 1 dimensión, es decir, una recta. En un espacio tridimensional, un hiperplano es un subespacio de dos dimensiones, un plano convencional. Para dimensiones p>3 no es intuitivo visualizar un hiperplano, pero el concepto de subespacio con p-1 dimensiones se mantiene.\n",
    "\n",
    "La definición de hiperplano para casos perfectamente separables linealmente resulta en un número infinito de posibles hiperplanos, lo que hace necesario un método que permita seleccionar uno de ellos como clasificador óptimo.\n",
    "\n",
    "La solución a este problema consiste en seleccionar como clasificador óptimo al que se conoce como _maximal margin hyperplane_ o hiperplano óptimo de separación, que se corresponde con el hiperplano que se encuentra más alejado de todas las observaciones de entrenamiento. Para obtenerlo, se debe calcular la distancia perpendicular de cada observación a un determinado hiperplano. La menor de estas distancias (conocida como margen) determina cómo de lejos está el hiperplano de las observaciones de entrenamiento. El _maximal margin hyperplane_ se define como el hiperplano que consigue un mayor margen, es decir, que la distancia mínima entre el hiperplano y las observaciones es lo más grande posible. Aunque esta idea suena razonable, no es posible aplicarla, ya que habría infinitos hiperplanos contra los que medir las distancias. En su lugar, se recurre a métodos de optimización.\n",
    "\n",
    "El proceso de optimización tiene la peculiaridad de que sólo las observaciones que se encuentran justo al margen o que lo violan influyen sobre el hiperplano. A estas observaciones se les conoce como vectores soporte (_vectors suport_) y son las que definen el clasificador obtenido.\n",
    "\n",
    "#### Los _kernels_ en SVM\n",
    "\n",
    "Hay veces en que no hay manera de encontrar un hiperplano que permita separar dos clases. En estos casos decimos que las clases no son linealmente separables. Para resolver este problema podemos utilizar el truco del núcleo .\n",
    "\n",
    "El truco del núcleo (_kernel trick_) consiste en utilizar una dimensión nueva en la que podamos encontrar un hiperplano para separar las clases. Se puede ver un un ejemplo en: https://www.youtube.com/watch?v=OdlNM96sHio\n",
    "\n",
    "Al igual que en el algoritmo visto anteriormente (KNN), las SVM también dependen de varios hiperparámetros. \n",
    "\n",
    "En este caso intentaremos optimizar dos hiperparámetros:\n",
    "\n",
    "  - **C**: es la regularización, es decir, el valor de penalización de los errores en la clasificación. Indica el compromiso entre obtener el hiperplano con el margen más grande posible y clasificar el máximo número de ejemplos correctamente. Probaremos los valores: 0.01, 0.1, 1, 10, 50, 100 y 200.\n",
    "  \n",
    "  - **Gama**: coeficiente que multiplica la distancia entre dos puntos en el kernel radial. Para decirlo a \"grosso modo\", cuanto más pequeño es gama, más influencia tienen dos puntos cercanos. Probaremos los valores: 0.001, 0.01, 0.1, 1 y 10.\n",
    "  \n",
    "Para validar el rendimiento del algoritmo con cada combinación de hiperparámetros utilizaremos validación cruzada (_cross-validation_) con 4 particiones estratificadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos las siguientes librerías necesarias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargar el conjunto de datos:\n",
    "(Nota: el conjunto de datos es el resultado de una fase de exploración, analisis y preparación previa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   producto idSecuencia  udsVenta  bolOpen  EnPromocion  anyomes  diasemana  \\\n",
      "0         0  2022-12-06  0.000000        1            0        2          1   \n",
      "1         1  2022-12-06  1.098612        1            0        2          1   \n",
      "2         2  2022-12-06  0.000000        1            0        2          1   \n",
      "3         3  2022-12-06  0.000000        1            0        2          1   \n",
      "4         4  2022-12-06  0.000000        1            0        2          1   \n",
      "\n",
      "   semana  media_7_dias  media_30_dias  venta_lag_1  venta_lag_7  venta_lag_30  \n",
      "0      48      2.120606       2.301086     2.833213     2.079442           0.0  \n",
      "1      48      1.874395       2.042219     2.079442     1.791759           0.0  \n",
      "2      48      1.844732       1.681282     2.302585     2.564949           0.0  \n",
      "3      48      1.186639       1.540582     1.098612     0.000000           0.0  \n",
      "4      48      1.571729       1.871285     2.302585     2.564949           0.0  \n"
     ]
    }
   ],
   "source": [
    "# Cargar el archivo CSV con los datos de ventas\n",
    "file_path = \"Data/VentasRdo.csv\"\n",
    "file_path = \"Data/VentasRdo_10productos.csv\"\n",
    "df = pd.read_csv(file_path, parse_dates=['idSecuencia'])\n",
    "\n",
    "df['producto']    = LabelEncoder().fit_transform(df['producto'])\n",
    "df['bolOpen']     = LabelEncoder().fit_transform(df['bolOpen'])\n",
    "df['EnPromocion'] = LabelEncoder().fit_transform(df['EnPromocion'])\n",
    "df['diasemana']   = LabelEncoder().fit_transform(df['diasemana'])\n",
    "df['semana']      = LabelEncoder().fit_transform(df['semana'])\n",
    "\n",
    "# Mostrar las primeras filas para verificar la carga\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definir las características (X) y la variable objetivo (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir las características (X) y la variable objetivo (y)\n",
    "X = df[['producto', 'bolOpen', 'EnPromocion','anyomes', 'diasemana', 'semana','media_7_dias','media_30_dias','venta_lag_1','venta_lag_7','venta_lag_30']]  # Características\n",
    "y = df['udsVenta']  # Variable objetivo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5608, 11)\n",
      "(5608,)\n",
      "(1402, 11)\n",
      "(1402,)\n"
     ]
    }
   ],
   "source": [
    "# Dividir el conjunto de datos en entrenamiento y prueba (80% entrenamiento, 20% prueba)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El SVR y otros modelos basados en gradiente o distancias suelen funcionar mejor cuando las variables están normalizadas o estandarizadas. Escalar las variables permite que todas contribuyan de manera equivalente al cálculo de las distancias y evita que las de mayor magnitud dominen el proceso de optimización. \n",
    "\n",
    "Incluso si algunas variables están en la misma escala, aplicar el mismo escalado a todo el conjunto asegura una transformación uniforme y evita posibles inconsistencias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalado de datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params ={\n",
    "    'C': [0.01, 0.1, 1, 10, 50, 100, 200],\n",
    "    'gamma': [0.001, 0.01, 0.1, 1, 10]\n",
    "}\n",
    "\n",
    "gs_svm = GridSearchCV( SVR(),  grid_params, verbose=1, cv=4, n_jobs = -1,return_train_score = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 35 candidates, totalling 140 fits\n"
     ]
    }
   ],
   "source": [
    "gs_svm_results = gs_svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score:  0.4910101014800806\n",
      "best_estimador:  SVR(C=50, gamma=0.01)\n",
      "best_paramas:  {'C': 50, 'gamma': 0.01}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>50</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.491010</td>\n",
       "      <td>0.031884</td>\n",
       "      <td>0.527143</td>\n",
       "      <td>0.008925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.489094</td>\n",
       "      <td>0.032636</td>\n",
       "      <td>0.533887</td>\n",
       "      <td>0.008938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.489082</td>\n",
       "      <td>0.029669</td>\n",
       "      <td>0.510831</td>\n",
       "      <td>0.009888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.489045</td>\n",
       "      <td>0.029367</td>\n",
       "      <td>0.498518</td>\n",
       "      <td>0.009237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.487860</td>\n",
       "      <td>0.033298</td>\n",
       "      <td>0.516167</td>\n",
       "      <td>0.009307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.487495</td>\n",
       "      <td>0.028940</td>\n",
       "      <td>0.496078</td>\n",
       "      <td>0.009792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>200</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.486711</td>\n",
       "      <td>0.029227</td>\n",
       "      <td>0.497703</td>\n",
       "      <td>0.010287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>50</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.486507</td>\n",
       "      <td>0.028503</td>\n",
       "      <td>0.493210</td>\n",
       "      <td>0.009391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>200</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.485746</td>\n",
       "      <td>0.033653</td>\n",
       "      <td>0.540829</td>\n",
       "      <td>0.008984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.477808</td>\n",
       "      <td>0.026543</td>\n",
       "      <td>0.481888</td>\n",
       "      <td>0.008568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.477013</td>\n",
       "      <td>0.032219</td>\n",
       "      <td>0.569550</td>\n",
       "      <td>0.008290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.472556</td>\n",
       "      <td>0.028030</td>\n",
       "      <td>0.476148</td>\n",
       "      <td>0.008698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.454968</td>\n",
       "      <td>0.026158</td>\n",
       "      <td>0.457249</td>\n",
       "      <td>0.007191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.427606</td>\n",
       "      <td>0.027162</td>\n",
       "      <td>0.435008</td>\n",
       "      <td>0.009460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.415762</td>\n",
       "      <td>0.038694</td>\n",
       "      <td>0.666396</td>\n",
       "      <td>0.007906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.394350</td>\n",
       "      <td>0.022052</td>\n",
       "      <td>0.395912</td>\n",
       "      <td>0.007945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.382094</td>\n",
       "      <td>0.019865</td>\n",
       "      <td>0.383882</td>\n",
       "      <td>0.009426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.346977</td>\n",
       "      <td>0.024360</td>\n",
       "      <td>0.898662</td>\n",
       "      <td>0.004265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>50</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.296369</td>\n",
       "      <td>0.051976</td>\n",
       "      <td>0.758158</td>\n",
       "      <td>0.008056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.296097</td>\n",
       "      <td>0.026735</td>\n",
       "      <td>0.990414</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.293619</td>\n",
       "      <td>0.025069</td>\n",
       "      <td>0.991059</td>\n",
       "      <td>0.000057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>0.293619</td>\n",
       "      <td>0.025069</td>\n",
       "      <td>0.991059</td>\n",
       "      <td>0.000057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>0.293619</td>\n",
       "      <td>0.025069</td>\n",
       "      <td>0.991059</td>\n",
       "      <td>0.000057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.217261</td>\n",
       "      <td>0.061095</td>\n",
       "      <td>0.796523</td>\n",
       "      <td>0.008067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.174004</td>\n",
       "      <td>0.006908</td>\n",
       "      <td>0.313981</td>\n",
       "      <td>0.008090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>200</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.109881</td>\n",
       "      <td>0.070423</td>\n",
       "      <td>0.833620</td>\n",
       "      <td>0.007408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.038068</td>\n",
       "      <td>0.008251</td>\n",
       "      <td>0.038900</td>\n",
       "      <td>0.005668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>0.019828</td>\n",
       "      <td>0.002809</td>\n",
       "      <td>0.990508</td>\n",
       "      <td>0.000063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.019828</td>\n",
       "      <td>0.002809</td>\n",
       "      <td>0.990508</td>\n",
       "      <td>0.000063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>0.019828</td>\n",
       "      <td>0.002809</td>\n",
       "      <td>0.990508</td>\n",
       "      <td>0.000063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>0.019828</td>\n",
       "      <td>0.002809</td>\n",
       "      <td>0.990508</td>\n",
       "      <td>0.000063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.015925</td>\n",
       "      <td>0.001794</td>\n",
       "      <td>0.928399</td>\n",
       "      <td>0.001144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.067948</td>\n",
       "      <td>0.008025</td>\n",
       "      <td>0.094241</td>\n",
       "      <td>0.001274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.077142</td>\n",
       "      <td>0.009306</td>\n",
       "      <td>-0.060147</td>\n",
       "      <td>0.001245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.112141</td>\n",
       "      <td>0.009215</td>\n",
       "      <td>-0.094911</td>\n",
       "      <td>0.002850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_C param_gamma  mean_test_score  std_test_score  mean_train_score  \\\n",
       "21      50        0.01         0.491010        0.031884          0.527143   \n",
       "26     100        0.01         0.489094        0.032636          0.533887   \n",
       "16      10        0.01         0.489082        0.029669          0.510831   \n",
       "11       1        0.01         0.489045        0.029367          0.498518   \n",
       "7      0.1         0.1         0.487860        0.033298          0.516167   \n",
       "25     100       0.001         0.487495        0.028940          0.496078   \n",
       "30     200       0.001         0.486711        0.029227          0.497703   \n",
       "20      50       0.001         0.486507        0.028503          0.493210   \n",
       "31     200        0.01         0.485746        0.033653          0.540829   \n",
       "15      10       0.001         0.477808        0.026543          0.481888   \n",
       "12       1         0.1         0.477013        0.032219          0.569550   \n",
       "6      0.1        0.01         0.472556        0.028030          0.476148   \n",
       "10       1       0.001         0.454968        0.026158          0.457249   \n",
       "2     0.01         0.1         0.427606        0.027162          0.435008   \n",
       "17      10         0.1         0.415762        0.038694          0.666396   \n",
       "5      0.1       0.001         0.394350        0.022052          0.395912   \n",
       "1     0.01        0.01         0.382094        0.019865          0.383882   \n",
       "13       1           1         0.346977        0.024360          0.898662   \n",
       "22      50         0.1         0.296369        0.051976          0.758158   \n",
       "18      10           1         0.296097        0.026735          0.990414   \n",
       "28     100           1         0.293619        0.025069          0.991059   \n",
       "33     200           1         0.293619        0.025069          0.991059   \n",
       "23      50           1         0.293619        0.025069          0.991059   \n",
       "27     100         0.1         0.217261        0.061095          0.796523   \n",
       "8      0.1           1         0.174004        0.006908          0.313981   \n",
       "32     200         0.1         0.109881        0.070423          0.833620   \n",
       "0     0.01       0.001         0.038068        0.008251          0.038900   \n",
       "24      50          10         0.019828        0.002809          0.990508   \n",
       "19      10          10         0.019828        0.002809          0.990508   \n",
       "29     100          10         0.019828        0.002809          0.990508   \n",
       "34     200          10         0.019828        0.002809          0.990508   \n",
       "14       1          10         0.015925        0.001794          0.928399   \n",
       "9      0.1          10        -0.067948        0.008025          0.094241   \n",
       "3     0.01           1        -0.077142        0.009306         -0.060147   \n",
       "4     0.01          10        -0.112141        0.009215         -0.094911   \n",
       "\n",
       "    std_train_score  \n",
       "21         0.008925  \n",
       "26         0.008938  \n",
       "16         0.009888  \n",
       "11         0.009237  \n",
       "7          0.009307  \n",
       "25         0.009792  \n",
       "30         0.010287  \n",
       "20         0.009391  \n",
       "31         0.008984  \n",
       "15         0.008568  \n",
       "12         0.008290  \n",
       "6          0.008698  \n",
       "10         0.007191  \n",
       "2          0.009460  \n",
       "17         0.007906  \n",
       "5          0.007945  \n",
       "1          0.009426  \n",
       "13         0.004265  \n",
       "22         0.008056  \n",
       "18         0.000298  \n",
       "28         0.000057  \n",
       "33         0.000057  \n",
       "23         0.000057  \n",
       "27         0.008067  \n",
       "8          0.008090  \n",
       "32         0.007408  \n",
       "0          0.005668  \n",
       "24         0.000063  \n",
       "19         0.000063  \n",
       "29         0.000063  \n",
       "34         0.000063  \n",
       "14         0.001144  \n",
       "9          0.001274  \n",
       "3          0.001245  \n",
       "4          0.002850  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('best_score: ',gs_svm_results.best_score_)\n",
    "print('best_estimador: ',gs_svm_results.best_estimator_)\n",
    "print('best_paramas: ',gs_svm_results.best_params_)\n",
    "\n",
    "resultados_svm = pd.DataFrame(gs_svm_results.cv_results_)\n",
    "resultados_svm.filter(regex = '(param.*|mean_t|std_t)')\\\n",
    "    .drop(columns = 'params')\\\n",
    "    .sort_values('mean_test_score', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.711913186708125\n",
      "MAE: 0.5294983604386788\n",
      "R^2: 0.511896666005193\n"
     ]
    }
   ],
   "source": [
    "#métricas\n",
    "y_pred = gs_svm_results.best_estimator_.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"R^2: {r2}\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
