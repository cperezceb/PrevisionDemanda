---
title: ''
author: ''
date: "Noviembre de 2024"
output:
  html_document:
    highlight: default
    number_sections: true
    theme: cosmo
    toc: true
    toc_depth: 3
    css: style.css
    includes:
      in_header: M2.854_Header.html
  pdf_document:
    toc: true
    toc_depth: '3'
---

```{r setup, include=FALSE,echo=TRUE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#Cargamos las librerias que nos van a ayudar a tratar los datos y su representación gráfica.

# ggplot2: para la visualización de gráficos
if (!require('ggplot2')) install.packages('ggplot2'); library('ggplot2')
# gráfico ridgeline
if (!require('ggridges')) install.packages('ggridges'); library('ggridges')
# https://cran.r-project.org/web/packages/dplyr/index.html
if (!require('dplyr')) install.packages('dplyr'); library('dplyr')
# https://cran.rstudio.com/bin/windows/contrib/4.0/gridExtra_2.3.zip
if (!require('grid')) install.packages('grid'); library(grid)
# https://cran.r-project.org/web/packages/dplyr/index.html
if (!require('tidyverse')) install.packages('tidyverse'); library('tidyverse'); library(readxl) 
# https://cran.rstudio.com/bin/windows/contrib/4.0/gridExtra_2.3.zip
if (!require('gridExtra')) install.packages('gridExtra'); library(gridExtra)
# Instalar y cargar el paquete dbscan, utilizado para la busqueda de datos anómalos
if(!require(dbscan)) install.packages("dbscan");library(dbscan)
# Instalar y cargar el paquete fuzzyjoin, permite la unión de dataframe de forma flexible
if(!require(fuzzyjoin)) install.packages("fuzzyjoin");library(fuzzyjoin)
# Instalar y cargar el paquete data.table, para optimizar el manejo de datasets grandes (problemas de rendimiento)
if(!require(data.table)) install.packages("data.table");library(data.table)
# Instalar y cargar el paquete lubridate, para trabajar con fechas (funciones como day(), year(), para comparar, restar, parsing)
if(!require(lubridate)) install.packages("lubridate");library(lubridate)
# Instalar y cargar el paquete cluster, para trabajar con algoritmos como kmeans
if(!require(cluster)) install.packages("cluster");library(cluster)

#analisis de la componente temporal
if(!require(forecast)) install.packages("forecast");library(forecast)
if(!require(tseries)) install.packages("tseries");library(tseries)
if(!require(lmtest)) install.packages("lmtest");library(lmtest)

#reshape2: para la transformación y manipulación de datos (melt y cast)
if(!require(reshape2)) install.packages("reshape2");library(reshape2)
#corrplot: para la visualización de matrices de correlación.
if(!require(corrplot)) install.packages("corrplot");library(corrplot)
```


# Diseño e implementación del trabajo

En este apartado estudiaremos los datos de los que disponemos (origen, características, peculiaridades) y trabajaremos en ellos para garantizar una estructura y calidad suficiente con la que poder hacer una buena predicción. En una segunda etapa, se evaluan diferentes algoritmos en busca de la mejor predicción. Finalmente, se cuantifica cual ha sido el impacto de mejora obtenida.

## Origen de los datos

Esta sección presenta los datos utilizados para el desarrollo del proyecto.

### Obtención de los datos

Los datos pertenecen a una empresa de distribución de productos para el automóvil, en la que se detalla información de unos 1000 productos totalmente anonizados. Los ha cedido la propia empresa y nos lo ha proporcionado nuestra tutora Lorena Polo Navarro. Contamos con información para la predicción de la demanda, como puede ser el histórico de las ventas, y con datos para cuantificar la mejora obtenida al aplicar el modelo resultante.


### Descripción de los datos

Contamos con 3 ficheros de Excel:

- Datos.xlsx formados por estas cuatro hojas: 01_Ventas, 02_Calendarios, 03_Promociones y 04_Stock.

    - 01_Ventas: Histórico de ventas de los 1000 productos. Y su estructura es la siguiente:
        - producto: identificador único del producto. Ejemplo: 1 
        - idSecuencia: identificador de fecha, cuando se produce la venta. Ejemplo: 20221105
        - udsVenta: total de unidades vendidas. Ejemplo: 40
    
    - 02_Calendarios: Identifica los festivos y los días de apertura del punto de venta.Y su estructura es la siguiente:
        - idSecuencia: identificador de fecha
        - bolOpen: identifica si el puesto de venta está abierto o cerrado. bolOpen = 1  punto de venta abierto; bolOpen = 0 punto de venta cerrado.
        - bolHoliday: identifica los días que son festivos. bolHoliday = 1  festivo; bolHoliday = 0 laboral. Hay festivos donde el punto de venta está abierto.
    
    - 03_Promociones: Periodos en la que se han lanzado campañas promocionales para cada producto.
        - producto:identificador único del producto. Ejemplo: 469
        - idSecuenciaIni:identificador de fecha, cuando empieza la promoción. Ejemplo: 20120927
        - idSecuenciaFin:identificador de fecha, cuando finaliza la promoción. Ejemplo: 20121121

    - 04_Stock: Contiene, para cada producto, el número de unidades en stock diario.
        - producto:identificador único del producto. Ejemplo: 240
        - idSecuencia: identificador de fecha. Ejemplo:20240103
        - udsStock: unidades en stock. Ejemplo: 71
        
- DatosCicloAprovisionamiento.xlsx con la información de abastecimiento de los productos, cada cuanto se lanza un pedido y el tiempo necesario de suministro. 

    - producto:identificador único del producto. Ejemplo: 1
    - diasEntrePedidos: número de días entre pedidos. Ejemplo: 14
    - diasLeadtime: cuantos días transcurren desde la orden del pedido hasta que llega el material. Ejemplo: 15
    

- DatosPrecioMedio.xlsx con el precio medio de cada producto.

    - producto:identificador único del producto. Ejemplo: 1
    - eurPrecioMedio: precio medio en euros del producto. Ejemplo:68.73


### Carga de los datos

Se carga cada uno de los conjuntos de datos en dataframes del sistema.

Fichero Datos.xlsx

```{r}

# Path del fichero Datos
archivo <- "data/Datos.xlsx"

# Cargar cada hoja a un dataframe
dfVenta      <- read_excel(archivo, sheet = "Venta")       %>% as_tibble()
dfCalendario <- read_excel(archivo, sheet = "Calendario")  %>% as_tibble()
dfPromocion  <- read_excel(archivo, sheet = "Promociones") %>% as_tibble() 
dfStock      <- read_excel(archivo, sheet = "Stock")       %>% as_tibble() 

```

Fichero DatosCicloAprovisionamiento.xlsx

```{r}
# Path del fichero Datos
archivo <- "data/DatosCicloAprovisionamiento.xlsx"

# Cargar cada hoja a un dataframe
dfCicloAprovisionamiento      <- read_excel(archivo, sheet = "Hoja1")       %>% as_tibble()
```

Fichero DatosPrecioMedio.xlsx

```{r}
# Path del fichero Datos
archivo <- "data/DatosPrecioMedio.xlsx"

# Cargar cada hoja a un dataframe
dfPrecioMedio      <- read_excel(archivo, sheet = "Hoja1")       %>% as_tibble()
```



## Exploración de los datos

En esta apartado vamos a hacer una exploración de los diferentes dataframes. 


### Venta

El dataframe `dfVenta` representa el histórico de ventas de cada producto.

Tiene un total de `r dim(dfVenta)[1]` registros y consta de `r ncol(dfVenta)` variables: `r paste(names(dfVenta), collapse = ", ")`.

Estructura del dataframe:

```{r}
str(dfVenta)
```

- producto: identificador del producto, 
- idSecuencia: fecha de la venta, 
- udsVenta: unidades vendidas.


Resumen estadístico:

```{r}
summary(dfVenta)
```

```{r}
resumen <- data.frame(
  ##Variable = names(dfVenta),
  ValoresDistintos = sapply(dfVenta, function(x) length(unique(x))),
  DesviaciónTípica = sapply(dfVenta, function(x) if(is.numeric(x)) sd(x, na.rm = TRUE) else NA)
)
print(resumen)
```

Pequeño muestreo:

```{r}
head(dfVenta,4)
```

Comprobamos posibles valores nulos

```{r}
colSums(is.na(dfVenta))
colSums(dfVenta=="")
```
Por lo tanto, en la tabla de ventas tenemos la evolución de las ventas de 894 productos, identificados por los códigos del 1 al 1000, desde el 5 de noviembre de 2022 hasta el 5 de noviembre de 2024 (732 días).

El número máximo de unidades vendidas es `r max(dfVenta$udsVenta, na.rm = TRUE)` , la mediana de las unidad vendidas es `r median(dfVenta$udsVenta, na.rm = TRUE)`, por lo que se explora el dataframe y se deduce que los días que no hay venta se registra con el valor 0; así que, tomando los días que se produce una venta, la media de las ventas es `r sprintf("%.2f",mean(dfVenta$udsVenta[dfVenta$udsVenta > 0], na.rm = TRUE))`  unidades, y la desviación típica la situan en `r sprintf("%.2f",sd(dfVenta$udsVenta[dfVenta$udsVenta > 0], na.rm = TRUE))`. El total de ventas es  `r sprintf("%.2f",sum(dfVenta$udsVenta[dfVenta$udsVenta > 0], na.rm = TRUE))`. No se contemplan las devoluciones al no encontrar valores negativos.


```{r}
# Nos quedamos sólo con las ventas (udsVenta>0)
ventas_filtradas <- dfVenta$udsVenta[dfVenta$udsVenta > 0]

# Media y desviación estándar
media <- mean(ventas_filtradas)
desviacion <- sd(ventas_filtradas)

# Histograma
histograma <- hist(ventas_filtradas, breaks = 30, col = "lightblue", 
                   main = "Distribución de Ventas (Unidades Vendidas > 0)", 
                   xlab = "Unidades Vendidas", ylab = "Frecuencia", border = "white")

# Distribución normal: 95% de los valores están dentro de ±2 desviaciones típicas.
abline(v = media, col = "red", lwd = 2, lty = 2) # Media
# abline(v = media + desviacion, col = "darkgreen", lwd = 2, lty = 2) # +1 desviación
# abline(v = media - desviacion, col = "darkgreen", lwd = 2, lty = 2) # -1 desviación
abline(v = media + 2 * desviacion, col = "orange", lwd = 2, lty = 2) # +2 desviaciones
abline(v = media - 2 * desviacion, col = "orange", lwd = 2, lty = 2) # -2 desviaciones
# abline(v = media + 3 * desviacion, col = "purple", lwd = 2, lty = 2) # +3 desviaciones
# abline(v = media - 3 * desviacion, col = "purple", lwd = 2, lty = 2) # -3 desviaciones

# Leyenda
legend("topright", legend = c("Media", "+/- 2 desviaciones"), 
       col = c("red", "orange"), lwd = 2, lty = 2)


# frecuencias por unidades vendidas.
#table(ventas_filtradas)

```

```{r}
# Representación de los primeros 15 productos
dfventas_filtradas15 <- dfVenta[dfVenta$producto <16, ]

# Crear la gráfica Ridgeline
ggplot(dfventas_filtradas15, aes(x = udsVenta, y = as.factor(producto), fill = ..x..)) +
  geom_density_ridges_gradient(scale = 3, rel_min_height = 0.01) +
  scale_fill_distiller(palette = "Spectral", name = "Uds Vendidas") +
  labs(title = "Ejemplo de distribución de las ventas de 15 Productos",
       x = "Unidades Vendidas",
       y = "Producto") +
  theme_ridges() +
  theme(legend.position = "right")
```


La tabla de ventas nos ayudará a analizar el comportamiento de las ventas, buscar patrones a la hora de predecir la demanda, ampliando el contexto con las promociones y días en el que está abierta la distribuidora.

### Calendario

El dataframe `dfCalendario` identifica las festividades y las fechas de apertura del punto de venta.

Tiene un total de `r dim(dfCalendario)[1]` registros y consta de `r ncol(dfCalendario)` variables: `r paste(names(dfCalendario), collapse = ", ")`.

- idSecuencia: fecha
- bolOpen: '1' identifica que el punto de venta está abierto; '0' permanece cerrado.
- bolHoliday: '1' se trata de un día festivo; '0' día laborable.


```{r}
summary(dfCalendario)

sapply(dfCalendario, function(x) length(unique(x)))

head(dfCalendario,4)
```

En el `dfCalendario` identifica las festividades y las fechas de apertura del punto de venta desde 06/11/2022 al 19/02/2025 (837 días). Hay días festivos en los que el punto de venta está abierto.


### Promoción

El dataframe `dfPromocion` contiene las campañas promocionales para cada producto. 

Tiene un total de `r dim(dfPromocion)[1]` registros y consta de `r ncol(dfPromocion)` variables: `r paste(names(dfPromocion), collapse = ", ")`.

- producto: identificador del producto,
- idSecuenciaIni: fecha de cuando empieza la promoción,
- idSecuenciaFin: fecha de cuando termina la promoción.

```{r}
summary(dfPromocion)

head(dfPromocion,4)

```

La primera promoción empieza en año 2011, ( `r as.character(min(dfPromocion$idSecuenciaIni, na.rm = TRUE))` ).

La última promoción finaliza en el año 2024, ( `r as.character(max(dfPromocion$idSecuenciaFin, na.rm = TRUE))` ).




### Stock

El dataframe `dfStock` proporciona el stock diario de cada uno de los productos desde el 6 de noviembre de 2022 hasta el 6 de noviembre de 2024.

Tiene un total de `r dim(dfStock)[1]` registros y consta de `r ncol(dfStock)` variables: `r paste(names(dfStock), collapse = ", ")`.

- producto: identificador del producto,
- idSecuencia: fecha de cuando es el stock,
- udsStock: unidades en stock.

```{r}
summary(dfStock)

sapply(dfStock, function(x) length(unique(x)))

head(dfStock,4)
```


Proporciona el stock diario para de los 894 productos desde el 6 de noviembre de 2022 hasta el 6 de noviembre de 2024 (732 días).
No hay stock negativos y el stock máximo es de 947, aunque el 3er cuartil se fija en 71 unidades.


```{r}
# Media y desviación estándar
media <- mean(dfStock$udsStock)
desviacion <- sd(dfStock$udsStock)


# Histograma de las ventas
 histograma <- hist(dfStock$udsStock, breaks = 30, col = "lightblue", 
                    main = "Distribución del stock", 
                    xlab = "Unidades", ylab = "Frecuencia", border = "white")

# Distribución normal: 95% de los valores están dentro de ±2 desviaciones típicas.
abline(v = media, col = "red", lwd = 2, lty = 2) # Media
abline(v = media + 2 * desviacion, col = "orange", lwd = 2, lty = 2) # +2 desviaciones
abline(v = media - 2 * desviacion, col = "orange", lwd = 2, lty = 2) # -2 desviaciones

# Leyenda
legend("topright", legend = c("Media", "+/- 2 desviaciones"), 
       col = c("red", "orange"), lwd = 2, lty = 2)

```

```{r}
# Representación de los primeros 15 productos
dfStock15 <- dfStock[dfStock$producto <16, ]

# Crear la gráfica Ridgeline
ggplot(dfStock15, aes(x = udsStock, y = as.factor(producto), fill = ..x..)) +
  geom_density_ridges_gradient(scale = 3, rel_min_height = 0.01) +
  scale_fill_viridis_c(name = "Stock", option = "C") +
  labs(title = "Ejemplo de distribución del Stock de 15 Productos",
       x = "Unidades de Stock",
       y = "Producto") +
  theme_ridges() +
  theme(legend.position = "right")
```


### Ciclo Aprovisionamiento

El dataframe `dfCicloAprovisionamiento` proporciona la información de abastecimiento de los productos; cada cuanto tiempo se lanza un pedido y el tiempo necesario de suministro. 

Tiene un total de `r dim(dfCicloAprovisionamiento)[1]` registros y consta de `r ncol(dfCicloAprovisionamiento)` variables: `r paste(names(dfCicloAprovisionamiento), collapse = ", ")`.

- producto:identificador único del producto. Ejemplo: 1
- diasEntrePedidos: número de días entre pedidos. Ejemplo: 14
- diasLeadtime: cuantos días transcurren desde la orden del pedido hasta que llega el material. Ejemplo: 15
    

```{r}
summary(dfCicloAprovisionamiento)

sapply(dfCicloAprovisionamiento, function(x) length(unique(x)))

head(dfCicloAprovisionamiento,4)
```

El número de productos de los que tenemos datos es 1000.
El promedio de días entre pedidos es `r sprintf("%.2f",mean(dfCicloAprovisionamiento$diasEntrePedidos))` días.
El promedio de días de suministro es `r sprintf("%.2f",mean(dfCicloAprovisionamiento$diasLeadtime))` días.

### Precio Medio

El dataframe `dfPrecioMedio` proporciona el precio medio de cada uno de los productos.

Tiene un total de `r dim(dfPrecioMedio)[1]` registros y consta de `r ncol(dfPrecioMedio)` variables: `r paste(names(dfPrecioMedio), collapse = ", ")`.

- producto:identificador único del producto. Ejemplo: 1
- eurPrecioMedio: precio medio en euros del producto. Ejemplo:68.73


```{r}
summary(dfPrecioMedio)

sapply(dfPrecioMedio, function(x) length(unique(x)))

head(dfPrecioMedio,4)
```

El número de productos de los que tenemos datos es 1000.
Los precios de los productos oscilan desde `r sprintf("%.2f",min(dfPrecioMedio$eurPrecioMedio))` que es el producto más barato hasta `r sprintf("%.2f",max(dfPrecioMedio$eurPrecioMedio))` que es el artículo más caro.


## Limpieza de datos y transformaciones realizadas

En este apartado se va a identificar y corregir (o eliminar) datos incorrectos, incompletos, duplicados o irrelevantes en los conjuntos de datos.

Esta fase es importante para garantizar que los datos sean precisos, consistentes y útiles, y para evitar que los análisis posteriores se vean sesgados.

Se llevan a cabo las siguientes tareas:

-  Eliminación de duplicados: Identificar y eliminar registros duplicados que pueden distorsionar los resultados.
-  Manejo de valores faltantes
-  Corrección de errores
-  Estandarización de formatos
-  Eliminar datos irrelevantes o incorrectos que pueden afectar la calidad del análisis (ruido).
-  Normalización de los valores de los datos.
-  Agregación: Resumir los datos en grupos.
-  Generación de nuevas variables.
-  Seleccionar subconjuntos de datos relevantes para el análisis específico.
-  Combinar datos de diferentes fuentes en un solo conjunto coherente.


### Transformación tipo de variables e identificadores de factores.

Comenzamos transformando las variables _fecha_ al tipo de datos Date, queremos que los algoritmos tengan el contexto temporal y no sean tratados como valores continuos que no tienen significado estadístico.

```{r}

#dfVenta: fecha de la venta
dfVenta$idSecuencia <- as.Date(as.character(dfVenta$idSecuencia), format = "%Y%m%d")

#dfCalendario: fecha de la tabla Calendario
dfCalendario$idSecuencia <- as.Date(as.character(dfCalendario$idSecuencia), format = "%Y%m%d")

#dfPromocion: las fechas que marcan los periodos de las promociones
dfPromocion$idSecuenciaIni <- as.Date(as.character(dfPromocion$idSecuenciaIni), format = "%Y%m%d")
dfPromocion$idSecuenciaFin <- as.Date(as.character(dfPromocion$idSecuenciaFin), format = "%Y%m%d")

#dfStock: la fecha de la medición del stock
dfStock$idSecuencia <- as.Date(as.character(dfStock$idSecuencia), format = "%Y%m%d")

```

Categorizamos las variables binarias _bolOpen_ y _bolHoliday_ del dataframe Calendario

```{r}

dfCalendario$bolOpen     <- as.factor(dfCalendario$bolOpen)
dfCalendario$bolHoliday  <- as.factor(dfCalendario$bolHoliday)

```


### Combinar dfVentas y dfCalendario

Añadimos la información que proporciona el conjunto de datos _calendario_, al histórico de ventas.

```{r}
 dfVenta <- merge(dfVenta, dfCalendario, by="idSecuencia", all.x = TRUE)
```

Comprobamos posibles valores nulos

```{r}
colSums(is.na(dfVenta))
colSums(dfVenta=="")
```

Estos valores a nulo en las columnas bolOpen, bolHoliday son debidos a que la tabla de ventas registra desde el día 05 de noviembre de 2022 y, como hemos visto en el apartado anterior, tanto el conjunto de datos calendario y stock, empiezan el 6 de noviembre de 2022. Por lo tanto, consideramos que nuestro registro empiece el día 06 de noviembre de 2022, y eliminamos las ventas del día 05 de noviembre de 2022.

```{r}
dfVenta <- dfVenta %>%
  filter(idSecuencia != as.Date("2022-11-05"))
```


### Promoción

Transformamos la tabla promoción para obtener un dataframe que identifique los días que un producto está en promoción, con la siguiente estructura: 
- producto: identificador del producto
- idSecuencia: día en el que está de promoción.

#### Descomponer periodos promociones

Para ello creamos una función que dado un producto y un periodo lo descomponga en los días que contiene el periodo promocional.

```{r}
# Función para expandir las fechas
DescomponerPeriodo <- function(producto, idSecuenciaIni, idSecuenciaFin) {
  # Fechas entre fechaInicio y fechaFin
  fechas <- seq.Date(idSecuenciaIni, idSecuenciaFin, by = "day")
  # Nuevo dataframe con el producto y las fechas
  data.frame(producto = producto, fecha = fechas)
}

```

Aplicamos la función al dataframe de promociones.

```{r}
# Usar la función DescomponerPeriodo para generar el nuevo dataframe
dfProductoEnPromocion <- do.call(rbind, mapply(DescomponerPeriodo, dfPromocion$producto, dfPromocion$idSecuenciaIni, dfPromocion$idSecuenciaFin, SIMPLIFY = FALSE))

# Ver el resultado
head(dfProductoEnPromocion)

```

#### Comprobar promociones solapadas

Comprobamos si puede haber más de una promoción activa para un mismo producto

```{r}
# transformamos a datatable
setDT(dfProductoEnPromocion)
PromocionesDuplicadas <- dfProductoEnPromocion[duplicated(dfProductoEnPromocion, by = c("producto", "fecha"))]
head(PromocionesDuplicadas)
```

```{r}
# Eliminar duplicados
dfProductoEnPromocion <- dfProductoEnPromocion %>%
  distinct(producto, fecha, .keep_all = TRUE)
```

#### Combinar con el histórico de ventas.

Combinamos la tabla de ventas con los datos de las promociones, de este modo sabremos si la venta se ha producido en periodo de promoción.


```{r}

# Crear columna EnPromoción (es la que añadiremos a Ventas)
dfProductoEnPromocion$EnPromocion <- 1

# Sólo nos interesa las promociones dentro del histórico de ventas
min_fecha_venta <- min(dfVenta$idSecuencia, na.rm = TRUE)
max_fecha_venta <- max(dfVenta$idSecuencia, na.rm = TRUE)

dfProductoEnPromocion <- dfProductoEnPromocion %>%
  filter(fecha >= min_fecha_venta & fecha <= max_fecha_venta)

str(dfProductoEnPromocion)
```

Combinar las promociones con la tabla de ventas, la variable EnPromocion identifica si el producto estaba o no en promoción en el momento de la venta.

```{r}
dfVenta <- merge(dfVenta, dfProductoEnPromocion,
                     by.x = c("producto", "idSecuencia"),
                     by.y = c("producto", "fecha"),
                     all.x = TRUE)

#los valores NA los sustituimos por 0
dfVenta$EnPromocion <- sapply(dfVenta$EnPromocion, function(x) if(is.na(x)) 0 else x)
#hacemos que la variable EnPromocion sea factor
dfVenta$EnPromocion <- factor(dfVenta$EnPromocion, levels = c(0, 1))

str(dfVenta)

```

### Stock

Completamos la información de Ventas con los datos de stock de cada producto/día

```{r}

dfVenta <- merge(dfVenta, dfStock,
                  by.X = c("producto","idSecuencia"),
                  by.y = c("producto", "idSecuencia"),
                  all.x = TRUE)

str(dfVenta)
head(dfVenta)
```


```{r}
# archivo <- "data/VentasRdo.csv"
# 
# # volcar los datos a un csv
# write.csv(dfVenta, archivo, row.names = FALSE)
```

### Nuevas variables

Añadimos al dataframe de Ventas algunas variables extraídas de la fecha de la venta que nos pueden ayudar a detectar patrones o simplemente a enterder un poco mejor el comportamiento de las ventas.

```{r}
#Variables a añadir (ejemplo idSecuencia= "2024-05-06"): anyo (año de la venta: 2024), mes (mes de la venta: 5), dia (día de la venta: 6), anyomes: 202405, dia_semana (día dentro de la semana: 1 - lunes), semana (semana del año: 19)

dfVenta <- dfVenta %>%
  mutate(
    anyo = as.factor(year(idSecuencia)),
    mes = as.factor(month(idSecuencia)),
    dia = as.factor(day(idSecuencia)),
    anyomes = as.factor(paste0(year(idSecuencia), sprintf("%02d", month(idSecuencia)))),
    diasemana = as.factor(lubridate::wday(idSecuencia, label = FALSE, week_start = 1)),
    semana = as.factor(isoweek(idSecuencia))
  )



```


Hacemos una exploración tras realizar las transformaciones.

Tiene un total de `r dim(dfVenta)[1]` registros y consta de `r ncol(dfVenta)` variables: `r paste(names(dfVenta), collapse = ", ")`.

Estructura del dataframe:

```{r}
str(dfVenta)
```

- producto: identificador del producto, 
- idSecuencia: fecha de la venta, 
- udsVenta: unidades vendidas.
- bolOpen: 1 identifica cuando el punto de venta está abierto.
- bolHoliday: 1 identifica si el día es festivo.
- EnPromocion: 1 identifica si el producto estaba en promoción en el momento de la venta.
- udsStock: el número de unidades que había al inicio del día en stock para ese artículo.
- anyo: año de cuando se produce la venta
- mes: número de mes en el que se produce la venta.
- dia: día de la venta
- anyomes: combinación del año y mes de la venta
- diasemana: el día de la semana que se produce la venta: 1-Lunes, 2-Martes,..., 7-Domingo.
- semana: número de la semana del año en la que se produce la venta.

Resumen estadístico:

```{r}
summary(dfVenta)
```

```{r}
resumen <- data.frame(
  ##Variable = names(dfVenta),
  ValoresDistintos = sapply(dfVenta, function(x) length(unique(x))),
  DesviaciónTípica = sapply(dfVenta, function(x) if(is.numeric(x)) sd(x, na.rm = TRUE) else NA)
)
print(resumen)
```

Pequeño muestreo:

```{r}
head(dfVenta,4)
```



Comprobamos de nuevo los valores nulos

```{r}
colSums(is.na(dfVenta))
colSums(dfVenta=="")
```

```{r}
colSums(dfVenta==0, na.rm = TRUE)
```
#### Tratamiento rotura de stock

Observamos que hay muchos días en los que el stock de los productos está a cero y por lo tanto son ventas que se han perdido.
Debemos inducir estas ventas. Previamente analizaremos como son las ventas para poder asignar el valor a las unidades vendidas.


#### ¿Las campañas de promoción influyen en las unidades vendidas de los productos?

En este apartado queremos analizar si las campañas de los productos influye en la cantidad de unidades vendidas. Específicamente, si los productos promocionados tienen mejor ventas, con un nivel de confianza del 95% y para un nivel de confianza del 90%. 

¿La venta media de los productos promocionados es significativamente mayor que la venta media de los productos sin promoción?

H0 : µVentasPromocion = µVentasNoPromocional

H1 : µVentasPromocion > µVentasNoPromocional

Análisis visual

```{r}
grid.newpage()

VentaPromocion <- dfVenta[dfVenta$EnPromocion==1,]
VentaNoPromocion <- dfVenta[dfVenta$EnPromocion==0,]

plotVentaPromocion <-  ggplot(VentaPromocion, aes(x = udsVenta)) +
                      geom_bar() +
                      geom_vline(aes(xintercept=median(udsVenta, na.rm=T)), colour='#2ca25f', linetype='dashed', lwd=1) +
                      ggtitle("(udsVenta) uds Vendidas - Venta Promocion")


plotVentaNoPromocion <- ggplot(VentaNoPromocion, aes(x = udsVenta)) +
                      geom_bar() +
                      geom_vline(aes(xintercept=median(udsVenta, na.rm=T)), colour='#2ca25f', linetype='dashed', lwd=1) +
                      ggtitle("(udsVenta) uds Vendidas - Venta No Promocion")


grid.arrange(plotVentaPromocion,plotVentaNoPromocion, ncol=2)
```

Test de igualdad de varianzas de las dos muestras,

```{r}
var.test(VentaPromocion$udsVenta, VentaNoPromocion$udsVenta)
```

t de Welch

```{r}
t.test(VentaPromocion$udsVenta, VentaNoPromocion$udsVenta, alternative="greater", var.equal=FALSE)
t.test(VentaPromocion$udsVenta, VentaNoPromocion$udsVenta, var.equal=FALSE, conf.level = 0.90)
```

```{r}
# Media de unidades vendidas en promoción
media_uds_promocion <- mean(dfVenta[dfVenta$EnPromocion == "1", "udsVenta"])

# Media de unidades vendidas fuera de promoción
media_uds_no_promocion <- mean(dfVenta[dfVenta$EnPromocion == "0", "udsVenta"])

```
El valor p es extremadamente pequeño, p-value < 2.2e-16, mucho menor que cualquier nivel de significancia p < 0.05, por lo tanto, rechazamos la hipótesis nula y afirmamos que, para un nivel de confianza del 95%, la venta media de los productos promocionados es mayor que la venta media de los productos sin promoción.
La media de las ventas de los productos promocionados es `r media_uds_promocion` y la media de las ventas no promocionadas es `r media_uds_no_promocion`.


comparación de las campañas de promoción para cada producto

```{r}
#Para cada producto, se calcula las unidades vendidas y el número de días, tanto en promoción y como no_promoción
ventas_promocion <- aggregate(udsVenta ~ producto, data = subset(dfVenta, EnPromocion == "1"), sum)
dias_promocion <- aggregate(idSecuencia ~ producto, data = subset(dfVenta, EnPromocion == "1"), function(x) length(unique(x)))

ventas_no_promocion <- aggregate(udsVenta ~ producto, data = subset(dfVenta, EnPromocion == "0"), sum)
dias_no_promocion <- aggregate(idSecuencia ~ producto, data = subset(dfVenta, EnPromocion == "0"), function(x) length(unique(x)))

# Media diaria de ventas para cada producto
media_diaria_promocion <- merge(ventas_promocion, dias_promocion, by = "producto")
media_diaria_promocion$media_diaria <- round(media_diaria_promocion$udsVenta / media_diaria_promocion$idSecuencia, 2)

media_diaria_no_promocion <- merge(ventas_no_promocion, dias_no_promocion, by = "producto")
media_diaria_no_promocion$media_diaria <- round(media_diaria_no_promocion$udsVenta / media_diaria_no_promocion$idSecuencia, 2)

# Unir los datos para la representación
media_diaria <- merge(
  media_diaria_promocion[, c("producto", "media_diaria")], 
  media_diaria_no_promocion[, c("producto", "media_diaria")], 
  by = "producto", 
  suffixes = c("_promocion", "_no_promocion"), 
  all = TRUE
)

# Gráfico de barras para cada producto
media_diaria_long <- reshape2::melt(media_diaria, id.vars = "producto", variable.name = "tipo", value.name = "media_diaria")

ggplot(media_diaria_long, aes(x = factor(producto), y = media_diaria, fill = tipo)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(x = "Producto", y = "Media Diaria de Ventas", title = "Comparación de Ventas Diarias en Promoción y No en Promoción por Producto") +
  theme_minimal()
```
Para mayor detalle de los 20 primeros artículos.

```{r}
media_diaria_top20produtos <- subset(media_diaria_long, producto <= 20)
ggplot(media_diaria_top20produtos, aes(x = factor(producto), y = media_diaria, fill = tipo)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(x = "Producto", y = "Media Diaria de Ventas", title = "Comparación de Ventas Diarias en Promoción y No en Promoción por Producto") +
  theme_minimal()
```
#### Ajuste de las ventas no realizadas por rotura de stock

Se observa que para la mayoría de los producto las campañas promocionales son beneficiosas y contribuye a un aumento de las ventas.
Aprovechando estos datos, vamos a actualizar los artículos que no sean podido vender por un problema de rotura de stock; por lo tanto, si la venta a cero se corresponde a un día de promoción, le asignaremos la media de unidades vendidas de ese artículo en promoción y si no estaba en promoción pues el valor será el valor no promocional.


```{r}
# Contabilizar roturas de stock y donde no ha habido ventas
total_rotura_stock <- nrow(dfVenta[dfVenta$udsStock == 0 & dfVenta$udsVenta == 0, ])

cat("Total de rotura de stock (sin ventas asociadas):", total_rotura_stock, "\n")
```


```{r}
# Añadimos la información de las medias a dfVenta
dfVenta <- merge(dfVenta, media_diaria, by = "producto", all.x = TRUE)

# Actualizamos udsVenta donde udsStock es 0 y udsVenta es 0, según este el artículo en promoción o no
# dfVenta <- dfVenta %>%
#   mutate(udsVenta = ifelse(udsStock == 0 & udsVenta == 0 & !is.na(media_diaria_promocion) & !is.na(media_diaria_no_promocion),
#                            ifelse(EnPromocion == 1, round(media_diaria_promocion), round(media_diaria_no_promocion)),
#                            udsVenta))

dfVenta <- dfVenta %>%
  mutate(udsVenta = ifelse(
    udsStock == 0 & udsVenta == 0,
    ifelse(
      EnPromocion == 1 & !is.na(media_diaria_promocion), 
      round(media_diaria_promocion, 2), 
      ifelse(!is.na(media_diaria_no_promocion), round(media_diaria_no_promocion, 2), udsVenta)
    ),
    udsVenta
  ))


# Borrar las columnas de las medias
# dfVenta <- dfVenta %>%
#   select(-media_diaria_promocion, -media_diaria_no_promocion)
```


Comprobamos tras realizar el ajuste de la unidades no vendidas.


```{r}
# Contabilizar roturas de stock y donde no ha habido ventas
total_rotura_stock <- nrow(dfVenta[dfVenta$udsStock == 0 & dfVenta$udsVenta == 0, ])

cat("Total de rotura de stock (sin ventas asociadas):", total_rotura_stock, "\n")

```
### Analisis visual de las ventas

-- Representación gráfica de ventas por diassemana
-- Representación gráfica de ventas por anyomes
-- Representación gráfica de ventas EnPromocion
-- Representación gráfica de ventas festivos-laborales

```{r}
# ventas por día de la semana
# Agrupar los datos por día de la semana y sumar las ventas
dfResumen <- dfVenta %>%
  group_by(diasemana) %>%
  summarise(udsVenta = sum(udsVenta))
ggplot(dfResumen, aes(x = diasemana, y = udsVenta, fill = diasemana)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = udsVenta), vjust = -0.5, color = "black") +  
  labs(title = "Ventas por Día de la Semana", x = "Día de la Semana", y = "Unidades Vendidas") +
  scale_fill_brewer(palette = "Set3") +
  theme_minimal() +
  theme(legend.position = "none") 


```

```{r}

# ventas por año-mes

ggplot(dfVenta, aes(x = anyomes, y = udsVenta)) +
  geom_bar(stat = "identity", fill = "skyblue") +
  geom_hline(yintercept = seq(10000, 40000, by = 10000), color = "dodgerblue4", linetype = "dashed") +
  labs(title = "Ventas por Año y Mes", x = "Año - Mes", y = "Unidades Vendidas") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))

```


```{r}

# Ventas por días festivos
ggplot(dfVenta, aes(x = bolHoliday, y = udsVenta)) +
  geom_bar(stat = "identity") +
  labs(title = "Ventas por Días Festivos", x = "Día Festivo (0=No; 1=Sí)", y = "Unidades Vendidas")

ggplot(dfVenta, aes(x = factor(bolHoliday), y = udsVenta)) +
  geom_bar(stat = "identity", fill = "skyblue") +
  geom_text(aes(label = udsVenta), vjust = -0.5, color = "black", size = 3.5) +
  labs(title = "Ventas por Días Festivos", x = "Día Festivo (0=No; 1=Sí)", y = "Unidades Vendidas") +
  theme_minimal() +
  theme(legend.position = "none")





```


### Outliers

Una definición general de Barnett y Lewis define un valor atípico en un conjunto de datos como una observación (o conjunto de observaciones) que parece ser inconsistente con ese conjunto de datos.

Los valores atípicos no son iguales a errores. Deben ser detectados, pero no necesariamente eliminados. Su inclusión en el análisis es una decisión estadística.

Para datos más o menos unimodales y distribuidos simétricamente, el método de caja y bigotes de Tukey para la detección de valores atípicos es a menudo apropiado. En este método, una observación es un valor atípico cuando es mayor que los llamados "bigotes" del conjunto de observaciones. El bigote superior se calcula sumando 1.5 veces el rango intercuartílico al tercer cuartil y redondeando a la observación inferior más cercana. El bigote inferior se calcula de manera similar.

```{r}
# boxplot.stats(dfVenta$udsVenta)$out
```


```{r}
# Calcular el IQR y los límites para identificar outliers
Q1 <- quantile(dfVenta$udsVenta, 0.25)
Q3 <- quantile(dfVenta$udsVenta, 0.75)
IQR <- Q3 - Q1
lower_bound <- Q1 - 1.5 * IQR
upper_bound <- Q3 + 1.5 * IQR

# Filtrar los outliers
outliers <- dfVenta %>%
  filter(udsVenta < lower_bound | udsVenta > upper_bound)

# Eliminar los outliers del dataframe original
dfVenta_clean <- dfVenta %>%
  filter(udsVenta >= lower_bound & udsVenta <= upper_bound)

# Visualizar los outliers con un boxplot
ggplot(dfVenta, aes(x = factor(0), y = udsVenta)) +
  geom_boxplot() +
  labs(title = "Boxplot de Unidades Vendidas", x = "", y = "Unidades Vendidas") +
  theme_minimal()

# Visualización con boxplot por producto
ggplot(dfVenta, aes(x = as.factor(producto), y = udsVenta)) +
  geom_boxplot(outlier.colour = "red") +
  labs(title = "Detección de outliers por producto", x = "Producto", y = "Unidades vendidas") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

#write.csv(outliers, "data/VentasRdoOutliers.csv", row.names = FALSE)
```

Se ha detectado 43,158 observaciones como outliers tras aplicar el método IQR. 
Es decir, valores de ventas (udsVenta) que están fuera de los límites establecidos por el método IQR.
Si los outliers reflejan eventos reales, como promociones o patrón estacional, los mantenemos, pero si no se ajustan a algún patron los ajustaremos como hicimos anteriormente con las ventas no realizadas por rotura de stock

```{r}
# Dataframe original como base
data <- dfVenta
```

- Analizamos como cambian las ventas (udsVenta) a lo largo del tiempo (mes, diasemana) y cómo se comportan por producto.

```{r}
# Distribución de ventas por mes
ggplot(data, aes(x = as.factor(mes), y = udsVenta)) +
  geom_boxplot(outlier.colour = "red") +
  labs(title = "Distribución de ventas mensuales", x = "Mes", y = "Unidades vendidas") +
  theme_minimal()
```


```{r}
# Distribución de ventas por mes
ggplot(data, aes(x = as.factor(anyomes), y = udsVenta)) +
  geom_boxplot(outlier.colour = "red") +
  labs(title = "Distribución de ventas anyo mes", x = "Mes", y = "Unidades vendidas") +
  theme_minimal()

```



- ventas por días de la semana

```{r}
# Evolución de ventas por días de la semana
ggplot(data, aes(x = as.factor(diasemana), y = udsVenta, group = diasemana)) +
  geom_boxplot(outlier.colour = "red") +
  labs(title = "Distribución de ventas por día de la semana", x = "Día de la semana (1 = Lunes)", y = "Unidades vendidas") +
  theme_minimal()

```

- Outliers específicos por promociones y festivos

```{r}
# Outliers específicos por promociones y festivos
outliers_data <- data %>%
  filter(udsVenta < lower_bound | udsVenta > upper_bound)

ggplot(outliers_data, aes(x = as.factor(EnPromocion), y = udsVenta, color = as.factor(bolHoliday))) +
  geom_jitter(alpha = 0.5) +
  labs(title = "Outliers según promoción y festivos", x = "Promoción (0 = No, 1 = Sí)", y = "Unidades vendidas") +
  theme_minimal()
```

Tras el analisis de las gráficas podemos considerar que hay un cierto patron de estacionalidad y que es normal que existan puntualemnte ventas altas, pero no se consideran errores. Eso sí vamos a limitar las ventas a un múltiplo razonable, así evitar que valores extremos influyan de manera desproporcionada. Clasificamos las ventas como Normal y Extremas (muy por encima del 3er cuartil de cada producto).

```{r}
# Calcular IQR para cada producto
stats_iqr <- dfVenta %>%
  group_by(producto) %>%
  summarise(
    Q1 = quantile(udsVenta, 0.25),
    Q3 = quantile(udsVenta, 0.75),
    IQR = Q3 - Q1
  )

# Unir las métricas al dataframe
dfVenta <- dfVenta %>%
  left_join(stats_iqr, by = "producto") %>%
  mutate(
    tipoVenta = case_when(
      udsVenta < Q1 - IQR ~ "Baja",
      udsVenta > Q3 + 2 * IQR ~ "Alta",
      TRUE ~ "Normal"
    )
  )%>%
  select(-Q1, -Q3, -IQR) 

# Representar gráficamente
ggplot(dfVenta, aes(x = tipoVenta)) +
  geom_bar(fill = c("#DA3E2F", "#87B6D9", "#8CCE7D")) +
  labs(title = "Identificación ventas extremas (IQR)",
       x = "Categoría de Venta",
       y = "Frecuencia") +
  theme_minimal()
```

__Ajuste de valores Outliers__

No queremos perder información ni distorsionar la realidad, las ventas extremas podrían ser reales, aunque no queremos un influencia grande. Por lo que, no se eliminan estos datos y los ajustamos al valor máximo de unidades del producto y de esta forma siguen siendo ventas importantes, pero no extremas.


Calculamos el máximo valor de udsVenta para cada producto, excluyendo las ventas clasificadas como "Alta". Posteriormente actualizamos los valores de udsVenta donde tipoVenta es "Alta".

```{r}
# Calcular los máximos de udsVenta, ventas='Normal'|"Baja"
max_udsVenta <- dfVenta %>%
  filter(tipoVenta != "Alta") %>%
  group_by(producto) %>%
  summarise(max_udsVenta = max(udsVenta, na.rm = TRUE))

dfVenta <- dfVenta %>%
  left_join(max_udsVenta, by = "producto")

# Actualizar udsVenta, tipoVenta es "Alta"
dfVenta <- dfVenta %>%
  mutate(udsVenta = ifelse(tipoVenta == "Alta", max_udsVenta, udsVenta)) %>%
  select(-max_udsVenta)  

```

Revisamos tras aplicar la transformación.

```{r}
# Calcular el IQR y los límites para identificar outliers
Q1 <- quantile(dfVenta$udsVenta, 0.25)
Q3 <- quantile(dfVenta$udsVenta, 0.75)
IQR <- Q3 - Q1
lower_bound <- Q1 - 1.5 * IQR
upper_bound <- Q3 + 1.5 * IQR

# Filtrar los outliers
outliers <- dfVenta %>%
  filter(udsVenta < lower_bound | udsVenta > upper_bound)

# Visualización con boxplot por producto
ggplot(dfVenta, aes(x = as.factor(anyomes), y = udsVenta)) +
  geom_boxplot(outlier.colour = "red") +
  labs(title = "Distribución de ventas anyo mes", x = "Mes", y = "Unidades vendidas") +
  theme_minimal()

#write.csv(outliers, "data/VentasRdoOutliers.csv", row.names = FALSE)
```

Siguen existiendo outlier, pero ya no están los valores extremos que puedan influir en los modelos de predicción.


## Estudio de la temporalidad

Descomposición de la serie temporal en componentes:

- Tendencia: Captura patrones a largo plazo en las ventas.
- Estacionalidad: Refleja patrones cíclicos repetitivos (por ejemplo, variaciones diarias, semanales o anuales).
- Ruido: Captura las variaciones aleatorias no explicadas.

```{r}
# Convertir 'idSecuencia' a Date y establecer como índice
dfVenta$idSecuencia <- as.Date(dfVenta$idSecuencia)
dfVenta <- dfVenta[order(dfVenta$idSecuencia), ]
tsVenta <- ts(dfVenta$udsVenta, start = c(2022, as.numeric(format(dfVenta$idSecuencia[1], "%j"))), frequency = 365)

# Descomposición de la serie temporal
#Captura patrones a largo plazo en las ventas.
descomposicion <- decompose(tsVenta)
plot(descomposicion)
```

```{r}
# Prueba de Dickey-Fuller aumentada para verificar la estacionariedad
#patrones cíclicos repetitivos 
adf_test <- adf.test(tsVenta)
print(adf_test)

```

La ADF, Con un p-valor de 0.01,  verifica que la serie es estacionaria.

Evalúar si hay heterocedasticidad (es decir, si la varianza de los errores no es constante).

```{r}
# Heterocedasticidad: Prueba de Breusch-Pagan
modelo <- lm(udsVenta ~ idSecuencia, data = dfVenta)
bp_test <- bptest(modelo)
print(bp_test)

```

El p-valor extremadamente bajo indica que existe heterocedasticidad en los datos. Debemos aplicar una función logaritmica sobre la variable udsVenta.

Autocorrelación (ACF) 
```{r}
# Autocorrelación
acf(tsVenta)
```

Los valores decrecen lentamente, podría indicar una tendencia o estacionalidad. Con autocorrelacion significativa al inicio.

Autocorrelación parcial (PACF)
```{r}
#autocorrelación parcial
pacf(tsVenta)
```

Los analisis de la temporalidad determinan que tenemos un conjunto de datos con estacionalidad, heterocedasticidad y que las ventas actuales dependen fuertemente de valores recientes

Transformaciones a realizar:

- Para mitigar la _heterocedasticidad_ aplicamos la función logaritmo sobre la variable (udsVenta)
- La estacionalidad identificada por la variables creadas: año, mes, anyomes, semana, día de la semana...(ya creadas)
- La autocorrelación, añadir nuevas variables que dependan de los valores recientes de las ventas...la detección de tendencias, patrones de ventas


_heterocedasticidad_ (varianza no constante)

```{r}
#aplicamos la función logaritmo sobre la variable (udsVenta)
dfVenta <- dfVenta %>%
  mutate(log_udsVenta = log(udsVenta + 1))

#Nota: cuando tengamos la predicción debemos deshacer el logaritmo
#predicciones_logaritmo     <- predict(modelo, datos)
#predicciones_udsVenta_real <- exp(predicciones_logaritmo) - 1
```

_Autocorrelación_
(mantenemos la escala con la udsVenta [transformación logaritmica])

```{r}
# Ventanas de tiempo (lags y promedios móviles) con idea que nos ayuden en la detección de tendencias, patrones de ventas, predicciones.
dfVenta <- dfVenta %>%
  group_by(producto) %>%
  arrange(idSecuencia) %>%
  mutate(
    media_7_dias = zoo::rollmean(log_udsVenta, k = 7, fill = NA, align = "right"),
    media_30_dias = zoo::rollmean(log_udsVenta, k = 30, fill = NA, align = "right"),
    venta_lag_1 = lag(log_udsVenta, 1),
    venta_lag_7 = lag(log_udsVenta, 7),
    venta_lag_30 = lag(log_udsVenta, 30)
  ) %>%
  ungroup()

str(dfVenta)
```

- producto: identificador del producto, 
- idSecuencia: fecha de la venta, 
- udsVenta: unidades vendidas.
- bolOpen: 1 identifica cuando el punto de venta está abierto.
- bolHoliday: 1 identifica si el día es festivo.
- EnPromocion: 1 identifica si el producto estaba en promoción en el momento de la venta.
- udsStock: el número de unidades que había al inicio del día en stock para ese artículo.
- anyo: año de cuando se produce la venta
- mes: número de mes en el que se produce la venta.
- dia: día de la venta
- anyomes: combinación del año y mes de la venta
- diasemana: el día de la semana que se produce la venta: 1-Lunes, 2-Martes,..., 7-Domingo.
- semana: número de la semana del año en la que se produce la venta.
- media_diaria_no_promocion: la media de ventas cuando el artículo no está en promoción.
- media_diaria_promocion: la media de ventas cuando el artículo está en promoción.
- media_7_dias: la media de ventas de los últimos 7 días.
- media_30_dias: la media de ventas de los últimos 30 días.
- venta_lag_1: unidades vendidas ayer (hace 1 día)
- venta_lag_7: unidades vendidas hace 7 día.
- venta_lag_30: unidades vendidas hace 1 día.

El cálculo de las nuevas variables toman como referencia las ventas recientes de los productos, por lo que, para los primeros datos de la muestra no disponemos de datos y por lo tanto tendremos nulo. Como solo afecta al primer mes, descartaremos estableceremos el corte a 06 de diciembre de 2022.

```{r}
colSums(is.na(dfVenta))
dfVenta <- dfVenta %>%
  filter(idSecuencia >= as.Date("2022-12-06"))
colSums(is.na(dfVenta))
```

## Clustering

Se aborda en otro fichero de python, donde se aplica la técnica del codo y se observa que nuestro conjunto de datos podríamos encontrar 4 cluster. 
Tras aplicar kmeans y dbscan obtenemos una representación gráfica que conlleva a dudas, por lo que utilizamos la métrica de Silhouette para evaluar la calidad de los cluster (distancia entre cluster y entre los puntos del cluster) y se concluye que no hay unos cluster bien diferenciados y por lo tanto, descartamos incluirla a dataset final.

## Estudio de la correlacion de los datos

Analizamos las relaciones entre las variables, para ello calculamos la matriz de correlación y representamos gráficamente. Si encontramos una fuerte correlación entre variables podemos simplificar el modelo.

```{r}
str(dfVenta)
```

En primer lugar eliminamos las variables media_diaria_no_promocion, media_diaria_promocion y udsStock que no nos van a ayudar a predicción de la demanda.

```{r}
dfVenta <- dfVenta %>% select(-media_diaria_promocion, -media_diaria_no_promocion)
```


```{r, fig.width=10, fig.height=10}
#la función cor en R solo calcula la correlación entre variables numéricas.
dfVenta$bolOpen <- as.numeric(dfVenta$bolOpen)-1 #añado -1 porque R lo transforma a 1 y 2 (0=1 y 2=1)
dfVenta$bolHoliday <- as.numeric(dfVenta$bolHoliday)-1
dfVenta$EnPromocion <- as.numeric(dfVenta$EnPromocion)-1

dfVenta$anyo <- as.numeric(dfVenta$anyo)
dfVenta$mes <- as.numeric(dfVenta$mes)
dfVenta$dia <- as.numeric(dfVenta$dia)
dfVenta$anyomes <- as.numeric(dfVenta$anyomes)
dfVenta$diasemana <- as.numeric(dfVenta$diasemana)
dfVenta$semana <- as.numeric(dfVenta$semana)


# Calcular la matriz de correlación
correlation_matrix <- cor(dfVenta[, sapply(dfVenta, is.numeric)], use = "complete.obs") #use=complete.obs excluir los valores NA de las variables media y lag,

# Crear el heatmap
corrplot(correlation_matrix, method = "color", tl.col = "black", tl.srt = 45, addCoef.col = "black", tl.cex = 0.8, number.cex = 0.7)
#print(correlation_matrix)
```


La correlación entre bolOpen y bolHoliday es de -0.9361820, una correlación negativa muy fuerte, por lo tanto, para nuestro modelo excluiremos bolHoliday, manteniendo los días que el punto de venta está abierto y descartando la información de los días festivos. Eliminamos una de ellas para evitar la
generación de un sesgo en la predicción.

```{r}
dfVenta <- dfVenta %>% select(-bolHoliday)
```

También se observa correlación entre las variables de temporalidad que hemos creado.

Respecto la variable udsVenta apenas hay correlación con el resto de variables.


## Relaciones lineales entre las unidades vendidas y diferentes variables independientes

Utilizaremos un modelo de regresión lineal (variables cuantitativas y cualitativas) para determinar qué factores son los más importantes y por lo tanto deben permanecer en nuestro modelo.

```{r}
# Transformar la variable producto a factor
dfVenta$producto <- as.factor(dfVenta$producto)
dfVenta$EnPromocion <- as.factor(dfVenta$EnPromocion)
dfVenta$bolOpen <- as.factor(dfVenta$bolOpen)
dfVenta$diasemana <- as.factor(dfVenta$diasemana)
dfVenta$semana <- as.factor(dfVenta$semana)

#variable objetivo: udsVenta (logaritmica)
Modelo_RegresionLineal <- lm(log_udsVenta~producto+EnPromocion+bolOpen+diasemana+semana+udsStock, data=dfVenta)
#summary(Modelo_RegresionLineal)

```

```{r}
#variable numérica
# Extraer el coeficiente y el p-valor de la variable udsStock
coef_udsStock <- coef(summary(Modelo_RegresionLineal))["udsStock", "Estimate"]
pval_udsStock <- coef(summary(Modelo_RegresionLineal))["udsStock", "Pr(>|t|)"]

# Imprimir los resultados
cat("Coeficiente de udsStock:", coef_udsStock, "\n")
cat("P-valor de udsStock:", pval_udsStock, "\n")
```

El coeficiente de udsStock es `r coef_udsStock`, es muy pequeño, lo que indica que udsStock tiene un impacto mínimo en udsVenta.
Un valor p > 0.05, `r pval_udsStock` , indica que udsStock no es un predictor significativo de udsVenta. 

```{r}
#variables categóticas
# ANOVA
anova_result <- anova(Modelo_RegresionLineal)
print(anova_result)

```

El analisis determinan que las variables son significativas y tienen un impacto sobre la variable udsVenta. La menos significativa de todas ellas, pero si que se debe considerar sería la variable semana.

Por lo tanto, la variable udsStock no es significativa y la eliminamos del conjunto de datos.

## Conjunto de datos final

Finalmente, el conjunto de datos con el vamos a trabajar tiene esta estructura:

```{r}
dfVenta <- dfVenta %>% select(producto,idSecuencia,log_udsVenta,bolOpen,EnPromocion,anyomes,diasemana,semana,media_7_dias,media_30_dias,venta_lag_1,venta_lag_7,venta_lag_30)

#renombramos
colnames(dfVenta)[colnames(dfVenta) == "log_udsVenta"] <- "udsVenta"
```


```{r}
str(dfVenta)
```
La estructura del conjunto de datos final es:

_variable objetivo_

- udsVenta: unidades vendidas, (normalizada, resuelve problemas de heterocedasticidad).

_variable básica_

- Producto: Identificador único del producto.
- idSecuencia: Fecha de la venta (clave temporal).
- bolOpen: Indica si el punto de venta está abierto o cerrado.
- EnPromocion: Información sobre si el producto está en promoción.

_contexto temporal_

- anyomes: Año y mes combinados.
- diasemana: Día de la semana para identificar patrones semanales.
- semana: Semana del año, para capturar variaciones estacionales más amplias.

_tendencias recientes y dependencias temporales_

- media_7_dias, media_30_dias: Promedios móviles para capturar la tendencia a corto y largo plazo.
- venta_lag_1, venta_lag_7, venta_lag_30: Ventas rezagadas para capturar dependencias temporales en las ventas.



```{r}

summary(dfVenta)
colSums(is.na(dfVenta))
colSums(dfVenta=="")

sapply(dfVenta, function(x) length(unique(x)))

head(dfVenta,4)
```



```{r}
archivo <- "data/VentasRdo.csv"
 
# volcar los datos a un csv
write.csv(dfVenta, archivo, row.names = FALSE)
```